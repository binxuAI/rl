## Introduction to Reinforcement Learning

Welcome! This course is jointly taught by UC Berkeley and the Tsinghua-Berkeley Shenzhen Institute (TBSI).

### Instructors
- Prof. Scott Moura (UC Berkeley) <smoura [at] berkeley.edu>
- Co-Instructor Saehong Park (UC Berkeley) <sspark [at] berkeley.edu>
- TA Xinyi Zhou (TBSI) <zxyyx48 [at] 163.com>

### Course Schedule

| China Time      | California Time |
| ----------- | ----------- |
| July 7, 8, 9, 10 (Tu-F)      | July 6, 7, 8, 9 (M-Th)       |
| July 14, 15, 16, 17 (Tu-F);   | July 13, 14, 15, 16, 17 (M-Th)        |
| all at 08:30-10:05 China Time | all at 5:30pm PT - 7:05pm PT |

**Add to Google Calendar:**
(<a target="_blank" href="https://calendar.google.com/event?action=TEMPLATE&amp;tmeid=NnVtNW02MGNsMjhpbzNtY2NzMmdtMzRzaTNfMjAyMDA3MDdUMDAzMDAwWiBzY290dC5tb3VyYUBt&amp;tmsrc=scott.moura%40gmail.com&amp;scp=ALL"><img border="0" src="https://www.google.com/calendar/images/ext/gc_button1_en.gif"></a>)

### Day-by-Day Schedule

| Day         | Topic       | Speaker | Pre-recorded Lecture | Slides / Notes | Real-time Lecture Recordings |
| :---        |    :----    |   :---  | :---: | :---: | ----- |
| 1  | 1a. Introduction - Course Org | Scott Moura   | [Zoom Recording](https://zoom.com.cn/rec/share/u814Do2uqXNLeKfozUzjZZxmQb_Laaa82iNK8_JZmEeig-Z1PuncW5UlR3m_LxjL) PW: 1e*OV@Re | [LEC1a Slides](LEC/LEC1a-Syllabus.pdf) | [Recording Link](https://zoom.com.cn/rec/share/vvFyDLfvq2ROR4nHuFjHB6EaTqHpT6a8hiUX-KIJzhxGAfzZ3ZikkPi7ayroZPQF) PW: 9L%JePa= |
|   | 1b. Introduction – History of RL  | Scott Moura   | [Zoom Recording](https://berkeley.zoom.us/rec/share/wstyK7bC5FJLGdKUsl6GWYssFICmX6a813dK86IKyE_pN5u-bIIahg1i3Qd79l63) PW: 1k.E69^o | [LEC1a Slides](LEC/LEC1b-Motivation.pdf) |  |
|   | 1c. Optimal Control Intro  | Scott Moura   | [Zoom Recording](https://berkeley.zoom.us/rec/share/w9dtdu3V_F9OXrPT70LfcZIDG6vJeaa8h3BI-PoLyko-4eAHZcKnv9BAkTH0YSoY) PW: 2B&=2@*@ | | |
| 2  | 2a. Dynamic Programming | Scott Moura   | [Zoom Recording](https://berkeley.zoom.us/rec/share/18kpNbLOtXNLeaeV0xzfXqorGYHKeaa8hCIX-_sMmUrFWuA2JThxmQodgJWLND4q) PW: 3F*1rg%? | [LEC2a Notes](LEC/LEC2a.pdf) | [Recording Link](https://zoom.com.cn/rec/share/3uMsFJGh52RJXo3Ms3vwZLViRJqiT6a81HMf_fAFxUoUp1pRornQ06N5_-yX8ToS) PW: 8Q?#51=J |
|   | 2b. Case Study: Linear Quadratic Regulator (LQR)  | Scott Moura   | [Zoom Recording](https://berkeley.zoom.us/rec/share/5f5_FpeqrVNJaZ3ixmWFXYkFEaDjaaa81iQdq6VbnUkaRrxRLV0VSB3GaHybWp3T) PW: 5Y#4=58& | [LEC2b Notes](LEC/LEC2b.pdf) |  |
| 3  | 3a. Policy Evaluation & Policy Improvement | Scott Moura   | [Zoom Recording](https://berkeley.zoom.us/rec/share/wO1FDuzU3T1JSKPExkjWf6kFEoTiX6a80SVP-PQKmE2BWrgjbS83xsz27WcivvFR) PW: 9N@%H4&@ | [LEC3a Notes](LEC/LEC3a.pdf) | [Recording Link](https://zoom.com.cn/rec/share/2Oh6Iazi2UpIZM_n0EL4e58YOLjEaaa80yMYqfULn0hvu2bj64Y3C30TcApY4MKl) PW: 1A@@0G63 |
|   | 3b. Policy Iteration Algo   | Scott Moura   | [Zoom Recording](https://berkeley.zoom.us/rec/share/19NxfpLS9l9LY5GcwmbkaLIuFIr4T6a82yFI_voNy0pVtbAW0hMvT1O-lN-t8rgM) PW: 6y+!+6#9 | [LEC3b Notes](LEC/LEC3b.pdf) |  |
|   | 3c. Case Study: LQR   | Scott Moura   | [Zoom Recording](https://berkeley.zoom.us/rec/share/3-1oDunf1k1JTs_h7WuOa409ONnLaaa8gCFIr_IJmBkxlev6szns32PnTIYtOmVU) PW: 6D@YkC&= | [LEC3c Notes](LEC/LEC3c.pdf) |  |
| 4  | 4a. Approximate DP: TD Error & Value Function Approx. | Scott Moura   | [Zoom Recording](https://berkeley.zoom.us/rec/share/_e1cIIvA50NLcoXO1FCPWo4sIoPVX6a82yUW-qVfyUtH6zOaO86RFhE_QuSJfwJQ) PW: 6v&78$We | [LEC4a Notes](LEC/LEC4a.pdf) | [Recording Link](https://zoom.com.cn/rec/share/ysJzKpDR2k1JGIX88BziRf8CBK2iT6a8hHUWr6UOyBk5KEiJOhidnM24_iYBESJX) PW: 4t=#ye7T |
|   | 4b. Case Study: LQR   | Scott Moura   | [Zoom Recording](https://berkeley.zoom.us/rec/share/5edacpvq23JOcomcr2XYVpY4Pq29aaa8hCZKqKUPmEy1q8Nx_a72s8_JfPj5I_Vf) PW: 1O^fh.8+ | [LEC4b Notes](LEC/LEC4b.pdf) | [Installation Recording](https://zoom.com.cn/rec/share/2MZbJZzgq2pObqfI2QLiBr96O6Xdaaa8g3cfq_oPnkjj1lG4U1-Ptroyzg18Bsm4) PW: 2s+83!eQ |
|   | 4c. Online RL with ADP | Scott Moura   | [Zoom Recording](https://berkeley.zoom.us/rec/share/vsdeI7_LyUNOTaOct2bBeqUfJN6-eaa8hiNM-qEEmhppZHbVUeF4b4yWrDPpWa7I) PW: 0q=.4378 | [LEC4c Notes](LEC/LEC4c.pdf) | |
| 5 | 5a. Actor-Critic Method | Scott Moura   | [Zoom Recording](https://berkeley.zoom.us/rec/share/1etNEpLA5ElJWI3syWLVQpY9G6_0aaa8gCAc-fMMy04P1Zy-hyxVZ4zMq3IUY1Sx) PW: 2y!@@#$7 | [LEC5a Notes](LEC/LEC5a.pdf) | [Recording Link](https://zoom.com.cn/rec/share/wNx4LL_N1URJZLPd2UGOHbAgELT9aaa8hidPr6YMyUmB6zYifcjslipXrzF2VVd0) PW: 1Z^6B28+ |
|   | 5b. Case Study: Offshore Wind | Scott Moura   | | [LEC5b Notes](LEC/LEC5b.pdf) | |
| 6 | 6a. Q-Learning | Saehong Park  | [Zoom Recording](https://berkeley.zoom.us/rec/share/2ZR8PrjP7nxOQpHHxkbHZ7d4F4C1eaa81XJL-aUMyk3thCUnngiGNtgzFY0jEwGk
) PW:5L=*%&2i | [LEC6 Notes](LEC/LEC4c.pdf) | |
|   | 6b. Q-Learning / Policy Gradient | Saehong Park   | | | |
| 7 | 7a. Policy Gradient / Actor-Critic | Saehong Park  | | | |
|   | 7b. Actor-Critic | Saehong Park   | | | |
| 8 | 8a. RL for Energy Systems | Saehong Park  | | | |
|   | 8b. Case Study: Battery Fast-charging | Saehong Park   | | | |


### Topic Outline
1. Optimal Control
2. Dynamic Programming
   1. Principal of Optimality & Value Functions
      - Case Study: Linear Quadratic Regulator (LQR)
3. Policy Evaluation & Policy Improvement
   1. Policy Iteration Algo & Variants
   - Case Study: LQR
4. Approximate Dynamic Programming (ADP)
   1. Temporal Difference (TD) Error
   2. Value Function Approximation
      - Case Study: LQR
   3. Online RL with ADP
   4. Actor-Critic Method
      - Case Study: Offshore Wind
5. Q-Learning
   1. Q-learning algorithm
   2. Advanced Q-learning algorithm, i.e., DQN
6. Policy Gradient
   
   1. Vanilla policy gradient (REINFORCE)
7. Actor-Critic using Policy Gradient
   1. Actor-Critic using Policy Gradient
   2. Advanced Actor-Critic algorithm, i.e., DDPG
8. RL for energy systems
   1. Case Study: Battery Fast-charging
   

### Lectures Notes
- [2020 Lecture Notes](Notes/LectureNotes_2020.pdf) [Updated 2020-7-08]
- [2019 Lecture Notes](Notes/LectureNotes_2019.pdf)


### Jupyter Notebook
- [Tenrsorflow review](TF_1.X_review-Shared.ipynb) [Updated 2020-7-12]


<!--
### Markdown

Markdown is a lightweight and easy-to-use syntax for styling your writing. It includes conventions for

```markdown
Syntax highlighted code block

# Header 1
## Header 2
### Header 3

- Bulleted
- List

1. Numbered
2. List

**Bold** and _Italic_ and `Code` text

[Link](url) and ![Image](src)
```

For more details see [GitHub Flavored Markdown](https://guides.github.com/features/mastering-markdown/).

### Jekyll Themes

Your Pages site will use the layout and styles from the Jekyll theme you have selected in your [repository settings](https://github.com/scott-moura/rl/settings). The name of this theme is saved in the Jekyll `_config.yml` configuration file.

### Support or Contact

Having trouble with Pages? Check out our [documentation](https://help.github.com/categories/github-pages-basics/) or [contact support](https://github.com/contact) and we’ll help you sort it out.
-->
